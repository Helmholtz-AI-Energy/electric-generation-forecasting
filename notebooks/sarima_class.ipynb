{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96058203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "import plotly.express as px\n",
    "from pmdarima.arima.utils import ndiffs, nsdiffs\n",
    "from pmdarima.arima import auto_arima\n",
    "from pmdarima import model_selection\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7069e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"6e68642c-8403-4caa-af31-bda40b8c67f6\" # web token for RESTful API\n",
    "country_code = \"10Y1001A1001A83F\" # Germany\n",
    "time_zone = \"Europe/Berlin\" # time zone for Germany\n",
    "start_date = \"20171225\"\n",
    "end_date = \"20180102\"\n",
    "downsample = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343a5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARIMADataset:\n",
    "    \"\"\"\n",
    "    Fetch and preprocess ENTSO-E load and generation data. Caluclate SARIMA predictions and residuals.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_date, \n",
    "        end_date,                          # overall end date\n",
    "        api_key, # web token for RESTful API\n",
    "        country_code = \"10Y1001A1001A83F\", # country code (default: Germany)\n",
    "        time_zone = \"Europe/Berlin\", # time zone for Germany\n",
    "        downsample = False\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize SARIMA dataset.\n",
    "        Params\n",
    "        ------\n",
    "        start_date : str\n",
    "                     overall start date as \"YYYYMMDD\"\n",
    "        end_date : str\n",
    "                   overall end date as \"YYYYMMDD\"\n",
    "        api_key : str\n",
    "                  web token for RESTfulAPI access to ENTSO-E transparency platform\n",
    "        country_code : str\n",
    "                       country code\n",
    "        time zone : str\n",
    "                    time zone\n",
    "        downsample : bool\n",
    "                     Downsample to 1h resolution or not.\n",
    "        \"\"\"\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.country = country_code\n",
    "        self.time_zone = time_zone\n",
    "        self.api_key = api_key\n",
    "        self.df = None\n",
    "        self.original_headers = None\n",
    "        self.errors = None\n",
    "        self.downsample = downsample\n",
    "        self.fetch_data()\n",
    "        #self.calculate_pslps()\n",
    "        #self.calculate_sarima()\n",
    "        #self.calculate_errors()\n",
    "    \n",
    "    def _get_load_intervals(self):\n",
    "        \"\"\"\n",
    "        Get time points for sequential data loading from ENTSO-E transparency platform.\n",
    "        \n",
    "        For one request, the time delta for loading data from the platform is limited to one year.\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.Series\n",
    "        pandas series with timestamps of time points to consider between start and end date\n",
    "        \"\"\"\n",
    "        # Convert start and end dates to timestamps.\n",
    "        start = pd.Timestamp(self.start_date, tz=self.time_zone)\n",
    "        end = pd.Timestamp(self.end_date, tz=self.time_zone)\n",
    "    \n",
    "        # Create series from start and end timestamps.\n",
    "        start_series = pd.Series(pd.Timestamp(self.start_date))\n",
    "        end_series = pd.Series(pd.Timestamp(self.end_date))\n",
    "        \n",
    "        # Create date range from start and end dates and determine year starts within range.\n",
    "        # Convert data range to series.\n",
    "        dates = pd.date_range(start=self.start_date, end=self.end_date, freq=\"YS\", inclusive=\"both\").to_series()\n",
    "    \n",
    "        # Check whether start date itself is year start.\n",
    "        # If not, prepend to dates to consider for data loading.\n",
    "        if not start.is_year_start:\n",
    "            dates = pd.concat([start_series, dates], ignore_index=True)\n",
    "    \n",
    "        # Check whether end date itself is year start.\n",
    "        # If not, append to dates to consider for data loading.\n",
    "        if not end.is_year_start:\n",
    "            dates = pd.concat([dates, end_series], ignore_index=True)\n",
    "            \n",
    "        return dates\n",
    "        \n",
    "        \n",
    "    def _load_data(self, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Load actual load and actual aggregated generation per production type for requested time interval.\n",
    "        Params\n",
    "        ------\n",
    "        start_date : str\n",
    "                     start date as \"yyyymmdd\"\n",
    "        end_date : str\n",
    "                   end date as \"yyyymmdd\"\n",
    "                    \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame with time points as indices and load + generation per type as columns.\n",
    "        \"\"\"\n",
    "        from entsoe import EntsoePandasClient\n",
    "        # Initialize client and settings.\n",
    "        client = EntsoePandasClient(api_key=self.api_key)\n",
    "        start = pd.Timestamp(start_date, tz=self.time_zone)\n",
    "        end = pd.Timestamp(end_date, tz=self.time_zone)\n",
    "        # Query data and save to dataframe.\n",
    "        df_load = client.query_load(self.country, start=start, end=end)\n",
    "        print(f\"Actual load has shape {df_load.shape}.\")\n",
    "        df_gen = client.query_generation(self.country, start=start, end=end, psr_type=None)\n",
    "        df_gen.columns = [\" \".join(a) for a in df_gen.columns.to_flat_index()]\n",
    "        print(f\"Actual generation per production type has shape {df_gen.shape}.\")\n",
    "        df_final = pd.concat([df_load, df_gen], axis=1) # Concatenate dataframes in columns dimension.\n",
    "        print(f\"Concatenated data frame has shape {df_final.shape}.\")\n",
    "        \n",
    "        return df_final\n",
    "\n",
    "    \n",
    "    def fetch_data(self, drop_consumption=True):\n",
    "        \"\"\"\n",
    "        Fetch actual load and generation per type from ENTSO-E transparency platform \n",
    "        for requested time interval. Set resulting dataframe as attribute.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        drop_consumption : Bool\n",
    "                           Drop columns containing actual consumption.\n",
    "        \"\"\"\n",
    "        # Determine sequence of dates to consider when loading data.\n",
    "        dates = self._get_load_intervals()\n",
    "        print(f\"Consider the following dates:\\n{dates}\")\n",
    "        df_list = []\n",
    "        \n",
    "        for i, _ in enumerate(dates):\n",
    "    \n",
    "            if i == dates.shape[0] - 1:\n",
    "                df_final = pd.concat(df_list, axis=0) # Concatenate dataframes along time axis (index).\n",
    "                df_final.index = pd.to_datetime(df_final.index, utc=True).tz_convert(tz=\"UTC+01:00\")\n",
    "    \n",
    "                # Drop columns containing actual consumption?\n",
    "                if drop_consumption:\n",
    "                    print(\"Dropping columns containing actual consumption...\")\n",
    "                    df_final.drop(list(df_final.filter(regex='Consumption')), axis=1, inplace=True)\n",
    "                original_headers = df_final.columns\n",
    "\n",
    "                print(\"Creating columns for PSLP calculation...\")\n",
    "                for header in original_headers:\n",
    "                    df_final[str(header) + \" PSLP\"] = pd.Series(dtype='float')\n",
    "                if self.downsample:\n",
    "                    print(\"Downsample to 1h resolution...\")\n",
    "                    df_final = df_final.resample('1H', axis='index').mean()\n",
    "                print(\"Returning final data frame...\")\n",
    "                self.df = df_final\n",
    "                self.original_headers = original_headers\n",
    "                return\n",
    "                \n",
    "            try:\n",
    "                print(f\"Trying to load data chunk for time interval [{dates[i]}, {dates[i+1]}]...\")\n",
    "                df_temp = self._load_data(start_date=dates[i], end_date=dates[i+1])\n",
    "                print(df_temp.shape)\n",
    "                df_list.append(df_temp)\n",
    "                print(\"Loading successful!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Loading failed!\", e)\n",
    "                continue\n",
    "\n",
    "    @staticmethod            \n",
    "    def get_pslp_category(date, weekday=None, holiday=None, country_code='DE'):\n",
    "        \"\"\"\n",
    "        Get PSLP category from date, weekday information, and holiday information.\n",
    "        0 : weekday\n",
    "        1 : Saturday\n",
    "        2 : Sunday and holiday\n",
    "        \n",
    "        Params\n",
    "        ------\n",
    "        date : str\n",
    "               date in 'YYYYMMDD' format\n",
    "        weekday : int\n",
    "                  corresponding weekday\n",
    "                  0 - Mon, 1 - Tue, 2 - Wed, 3 - Thu, 4 - Fri, 5 - Sat, 6 - Sun\n",
    "        holiday : Bool\n",
    "                  True if public holiday, False if not.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        int : PSLP category\n",
    "        \"\"\"\n",
    "        # Convert string-type date to datetime object.\n",
    "        if type(date) is str:\n",
    "            date = pd.to_datetime(date)\n",
    "        \n",
    "        # Assign weekday if not given.\n",
    "        if weekday is None:\n",
    "            weekday = date.weekday()\n",
    "        \n",
    "        # Assign holiday category if not given.\n",
    "        if holiday is None:\n",
    "            import holidays\n",
    "            holiday = date in holidays.country_holidays(country_code)\n",
    "        \n",
    "        # Special treatment for Christmas eve and New year's eve as Saturdays.\n",
    "        if ( date.day == 24 or date.day == 31 ) and date.month == 12 and weekday != 6:\n",
    "            pslp_category = 1\n",
    "        # weekdays\n",
    "        elif weekday < 5 and holiday is False:\n",
    "            pslp_category = 0\n",
    "        # Saturdays\n",
    "        elif weekday == 5 and holiday is False:\n",
    "            pslp_category = 1\n",
    "        # Sundays and holidays\n",
    "        elif weekday == 6 or holiday is True:\n",
    "            pslp_category = 2\n",
    "        return pslp_category\n",
    "    \n",
    "    \n",
    "    def _assign_pslp_categories(self, country_code=\"DE\"):\n",
    "        \"\"\"\n",
    "        Assign PSLP categories to dates in dataframe's datetime index.\n",
    "    \n",
    "        0 is weekday, 1 is Saturday, 2 is Sunday or holiday.\n",
    "        Special treatment for Christmas eve and New Year's eve (as Saturdays).\n",
    "    \n",
    "        Params\n",
    "        ------\n",
    "        df : pandas.Dataframe\n",
    "        country_code : str\n",
    "                       country to determine holidays for\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.Dataframe\n",
    "        Dataframe amended by weekday information, holiday information, and PSLP category\n",
    "        \"\"\"\n",
    "    \n",
    "        import holidays\n",
    "        \n",
    "        # Get holidays in specified country.\n",
    "        country_holidays = holidays.country_holidays(country_code) # Passing a state is also possible!\n",
    "    \n",
    "        s = self.df.index.to_series()                                # Convert datetime index to series.\n",
    "        dates = s.dt.date                                       # Get plain dates from datetime objects.\n",
    "        weekdays = s.dt.weekday                                 # Get weekdays from datetime objects.\n",
    "        holidays = [date in country_holidays for date in dates] # Determine holidays.\n",
    "        pslp_category = []\n",
    "        \n",
    "        for d, wd, hd in zip(dates, weekdays, holidays):\n",
    "            pslp_category.append(self.get_pslp_category(d, wd, hd))\n",
    "            \n",
    "        self.df[\"PSLP Category\"] = pslp_category\n",
    "        self.df[\"Holiday\"] = holidays\n",
    "        self.df[\"Weekday\"] = weekdays\n",
    "    \n",
    "    \n",
    "    def calculate_residuals(self):\n",
    "        \"\"\"\n",
    "        Calculate residuals of actual data w.r.t PSLPs.\n",
    "        \"\"\"\n",
    "        for header in self.original_headers:\n",
    "            self.df[header+\" Residuals\"] = self.df[header] - self.df[header+\" SARIMA\"]\n",
    "    \n",
    "    \n",
    "    def plot_data(self):\n",
    "        \"\"\"\n",
    "        Plot preprocessed load and generation data.\n",
    "        \"\"\"\n",
    "        from plotly.subplots import make_subplots\n",
    "        import plotly.graph_objects as go\n",
    "    \n",
    "        num_rows = len(self.original_headers)\n",
    "        \n",
    "        fig = make_subplots(rows=num_rows, cols=1, subplot_titles=(self.original_headers))\n",
    "    \n",
    "        for i, header in enumerate(self.original_headers):\n",
    "            fig.add_trace(go.Scatter(x = self.df.index, y = self.df[header], name=header), row=i+1, col=1)\n",
    "            fig.add_trace(go.Scatter(x = self.df.index, y = self.df[header+\" PSLP\"], name=header+\" PSLP\"), row=i+1, col=1)\n",
    "            fig.add_trace(go.Scatter(x = self.df.index, y = self.df[header+\" Residuals\"], name=header+\" Residuals\"), row=i+1, col=1)\n",
    "    \n",
    "        fig.update_layout(height=10000, width=1200)\n",
    "        fig.show()\n",
    "        \n",
    "       \n",
    "    def calculate_errors(self):\n",
    "        \"\"\"\n",
    "        Calculate forecasting errors for preprocessed ENTSO-E load and generation data.  \n",
    "        \"\"\"\n",
    "        from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "        errors = {}\n",
    "        for header in self.original_headers:\n",
    "            temp = pd.concat([self.df[header], self.df[header+\" PSLP\"]], axis=1).dropna()\n",
    "            mae = mean_absolute_error(temp[header], temp[header+\" PSLP\"])\n",
    "            mape = mean_absolute_percentage_error(temp[header], temp[header+\" PSLP\"])\n",
    "            mse = mean_squared_error(temp[header], temp[header+\" PSLP\"])\n",
    "            errors[header] = {\"MAE\": mae, \"MAPE\": mape, \"MSE\": mse}\n",
    "        self.errors = errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7251161f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider the following dates:\n",
      "0   2017-12-25\n",
      "1   2018-01-01\n",
      "2   2018-01-02\n",
      "dtype: datetime64[ns]\n",
      "Trying to load data chunk for time interval [2017-12-25 00:00:00, 2018-01-01 00:00:00]...\n",
      "Actual load has shape (672, 1).\n",
      "Actual generation per production type has shape (672, 32).\n",
      "Concatenated data frame has shape (672, 33).\n",
      "(672, 33)\n",
      "Loading successful!\n",
      "Trying to load data chunk for time interval [2018-01-01 00:00:00, 2018-01-02 00:00:00]...\n",
      "Actual load has shape (96, 1).\n",
      "Actual generation per production type has shape (96, 20).\n",
      "Concatenated data frame has shape (96, 21).\n",
      "(96, 21)\n",
      "Loading successful!\n",
      "Dropping columns containing actual consumption...\n",
      "Creating columns for PSLP calculation...\n",
      "Downsample to 1h resolution...\n",
      "Returning final data frame...\n"
     ]
    }
   ],
   "source": [
    "SarimaData = SARIMADataset(start_date, end_date, api_key, country_code, time_zone, downsample=downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc72c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autocorrelations(data):\n",
    "    \"\"\"Plot ACF and PACF for given data.\"\"\"\n",
    "    plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
    "    # Original series\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    axes[0, 0].plot(data.to_numpy()); axes[0, 0].set_title(f'Original Series')\n",
    "    plot_acf(data.to_numpy(), ax=axes[0, 1])\n",
    "    plot_pacf(data.to_numpy(), ax=axes[0, 2], method='ywm')\n",
    "\n",
    "    # 1st-order differencing\n",
    "    axes[1, 0].plot(data.diff().to_numpy()); axes[1, 0].set_title(f'1st-Order Differencing')\n",
    "    plot_acf(data.diff().dropna().to_numpy(), ax=axes[1, 1])\n",
    "    plot_pacf(data.to_numpy(), ax=axes[1, 2], method='ywm')\n",
    "\n",
    "    # 2nd-order differencing\n",
    "    axes[2, 0].plot(data.diff().diff().to_numpy()); axes[2, 0].set_title(f'2nd-Order Differencing')\n",
    "    plot_acf(data.diff().diff().dropna().to_numpy(), ax=axes[2, 1])\n",
    "    plot_pacf(data.to_numpy(), ax=axes[2, 2], method='ywm')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f39e300f-0bb6-4e12-acc2-a365c35485a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01 00:00:00+01:00    45433.25\n",
      "2018-01-01 01:00:00+01:00    44270.00\n",
      "2018-01-01 02:00:00+01:00    43195.75\n",
      "2018-01-01 03:00:00+01:00    42527.50\n",
      "2018-01-01 04:00:00+01:00    42515.75\n",
      "2018-01-01 05:00:00+01:00    42278.00\n",
      "2018-01-01 06:00:00+01:00    41209.25\n",
      "2018-01-01 07:00:00+01:00    41799.25\n",
      "2018-01-01 08:00:00+01:00    42876.50\n",
      "2018-01-01 09:00:00+01:00    45234.25\n",
      "2018-01-01 10:00:00+01:00    47787.25\n",
      "2018-01-01 11:00:00+01:00    50409.50\n",
      "2018-01-01 12:00:00+01:00    51930.50\n",
      "2018-01-01 13:00:00+01:00    50812.00\n",
      "2018-01-01 14:00:00+01:00    49617.00\n",
      "2018-01-01 15:00:00+01:00    49771.50\n",
      "2018-01-01 16:00:00+01:00    51873.25\n",
      "2018-01-01 17:00:00+01:00    55379.75\n",
      "2018-01-01 18:00:00+01:00    56178.00\n",
      "2018-01-01 19:00:00+01:00    54823.25\n",
      "2018-01-01 20:00:00+01:00    52245.00\n",
      "2018-01-01 21:00:00+01:00    50241.50\n",
      "2018-01-01 22:00:00+01:00    49467.00\n",
      "2018-01-01 23:00:00+01:00    46538.75\n",
      "Freq: H, Name: Actual Load, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data_test = SarimaData.df[\"Actual Load\"].loc[\"2018-01-01\"]\n",
    "print(data_test)\n",
    "#plot_autocorrelations(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039d7537-ad32-499b-87e8-b71f26831cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, train_fraction=0.75, seasonal_cycle=96):\n",
    "    \"\"\"\n",
    "    Perform season-based train-test split of input data.\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "         overall dataset\n",
    "    train_fraction : float\n",
    "                     fraction of data to use for training\n",
    "    seasonal_cycle : int\n",
    "                     number of data points in each season\n",
    "                     Default 96 corresponds to 15min time resolution.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_train : pandas.DataFrame\n",
    "               train dataset\n",
    "    df_test : pandas.DataFrame\n",
    "              test dataset\n",
    "    \"\"\"\n",
    "    overall_days = int(SarimaData.df.shape[0] / seasonal_cycle)\n",
    "    train_days = int(train_fraction * overall_days)\n",
    "    test_days = overall_days - train_days\n",
    "    return model_selection.train_test_split(df, train_size=train_days, test_size=test_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9a3027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-compute (seasonal) differencing order to accelerate auto-ARIMA...\n",
      "Differencing order is 0. Seasonal differencing order is 0.\n"
     ]
    }
   ],
   "source": [
    "seasonal_cycle = 96\n",
    "train_fraction = 0.75\n",
    "data = SarimaData.df[\"Actual Load\"]\n",
    "data_train, data_test = split_train_test(data, train_fraction=train_fraction, seasonal_cycle=seasonal_cycle)\n",
    "print(\"Pre-compute (seasonal) differencing order to accelerate auto-ARIMA...\")\n",
    "# Estimate order of differencing d by performing a stationarity test for different d's. \n",
    "# Selects max. value d for which time series is judged stationary by statistical test.\n",
    "# Default unit root test of stationarity: Kwiatkowski–Phillips–Schmidt–Shin (KPSS)\n",
    "d = ndiffs(data, test='kpss')\n",
    "# Estimate order of seasonal differencing D by performing stationarity test of seasonality for different D's. \n",
    "# Selects max. value D for which time series is judged seasonally stationary by statistical test.\n",
    "# Default unit root test of stationarity: Osborn-Chui-Smith-Birchenhall (OCSB)\n",
    "D = nsdiffs(data, m=seasonal_cycle, test='ocsb')\n",
    "print(f\"Differencing order is {d}. Seasonal differencing order is {D}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a3ff274-5998-451d-ae1a-e90870f2816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically discover optimal order for SARIMAX model with `auto_arima`...\n",
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,0,1)(1,0,1)[96] intercept   : AIC=3281.322, Time=87.64 sec\n",
      " ARIMA(0,0,0)(0,0,0)[96] intercept   : AIC=3951.327, Time=0.05 sec\n",
      " ARIMA(1,0,0)(1,0,0)[96] intercept   : AIC=inf, Time=17.43 sec\n",
      " ARIMA(0,0,1)(0,0,1)[96] intercept   : AIC=inf, Time=46.57 sec\n",
      " ARIMA(0,0,0)(0,0,0)[96]             : AIC=4707.054, Time=0.03 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m max_P \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      9\u001b[0m max_Q \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mauto_arima\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mstart_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                   \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mstart_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_q\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmax_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmax_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_q\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mstart_P\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mstart_Q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_Q\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmax_P\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmax_Q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_Q\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_cycle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m                  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDONE.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/pmdarima/arima/auto.py:701\u001b[0m, in \u001b[0;36mauto_arima\u001b[0;34m(y, X, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;66;03m# init the stepwise model wrapper\u001b[39;00m\n\u001b[1;32m    670\u001b[0m     search \u001b[38;5;241m=\u001b[39m solvers\u001b[38;5;241m.\u001b[39m_StepwiseFitWrapper(\n\u001b[1;32m    671\u001b[0m         y,\n\u001b[1;32m    672\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msarimax_kwargs,\n\u001b[1;32m    699\u001b[0m     )\n\u001b[0;32m--> 701\u001b[0m sorted_res \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _return_wrapper(sorted_res, return_valid_fits, start, trace)\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/pmdarima/arima/_auto_solvers.py:333\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# NOTE: k changes for every fit, so we might need to bail halfway\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# through the loop, hence the multiple checks.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m P \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_k \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m--> 333\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    334\u001b[0m     P \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/pmdarima/arima/_auto_solvers.py:233\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper._do_fit\u001b[0;34m(self, order, seasonal_order, constant)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (order, seasonal_order, constant) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_dict:\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# increment the number of fits\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 233\u001b[0m     fit, fit_time, new_ic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_arima\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# use the orders as a key to be hashed for\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# the dictionary (pointing to fit)\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_dict[(order, seasonal_order, constant)] \u001b[38;5;241m=\u001b[39m fit\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/pmdarima/arima/_auto_solvers.py:506\u001b[0m, in \u001b[0;36m_fit_candidate_model\u001b[0;34m(y, X, order, seasonal_order, start_params, trend, method, maxiter, fit_params, suppress_warnings, trace, error_action, out_of_sample_size, scoring, scoring_args, with_intercept, information_criterion, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m fit \u001b[38;5;241m=\u001b[39m ARIMA(order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order,\n\u001b[1;32m    499\u001b[0m             start_params\u001b[38;5;241m=\u001b[39mstart_params, trend\u001b[38;5;241m=\u001b[39mtrend, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    500\u001b[0m             maxiter\u001b[38;5;241m=\u001b[39mmaxiter, suppress_warnings\u001b[38;5;241m=\u001b[39msuppress_warnings,\n\u001b[1;32m    501\u001b[0m             out_of_sample_size\u001b[38;5;241m=\u001b[39mout_of_sample_size, scoring\u001b[38;5;241m=\u001b[39mscoring,\n\u001b[1;32m    502\u001b[0m             scoring_args\u001b[38;5;241m=\u001b[39mscoring_args,\n\u001b[1;32m    503\u001b[0m             with_intercept\u001b[38;5;241m=\u001b[39mwith_intercept, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m     \u001b[43mfit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# for non-stationarity errors or singular matrices, return None\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (LinAlgError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m v:\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/pmdarima/arima/arima.py:603\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[0;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[1;32m    600\u001b[0m         X \u001b[38;5;241m=\u001b[39m safe_indexing(X, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_exog \u001b[38;5;241m-\u001b[39m cv))\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# Internal call\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# now make a forecast if we're validating to compute the\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;66;03m# out-of-sample score\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;66;03m# get the predictions (use self.predict, which calls forecast\u001b[39;00m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;66;03m# from statsmodels internally)\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/pmdarima/arima/arima.py:524\u001b[0m, in \u001b[0;36mARIMA._fit\u001b[0;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 524\u001b[0m         fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m _fit_wrapper()\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/pmdarima/arima/arima.py:510\u001b[0m, in \u001b[0;36mARIMA._fit.<locals>._fit_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    507\u001b[0m _maxiter \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m, _maxiter)\n\u001b[1;32m    509\u001b[0m disp \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 510\u001b[0m fitted \u001b[38;5;241m=\u001b[39m \u001b[43marima\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_maxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arima, fitted\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/statsmodels/tsa/statespace/mlemodel.py:704\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         flags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhessian_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optim_hessian\n\u001b[1;32m    703\u001b[0m     fargs \u001b[38;5;241m=\u001b[39m (flags,)\n\u001b[0;32m--> 704\u001b[0m     mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMLEModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mfargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mskip_hessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/statsmodels/base/model.py:563\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    562\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[0;32m--> 563\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[1;32m    573\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/statsmodels/base/optimizer.py:241\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    238\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[1;32m    240\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[0;32m--> 241\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[1;32m    247\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[1;32m    248\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[1;32m    250\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/statsmodels/base/optimizer.py:651\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[1;32m    649\u001b[0m     func \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m--> 651\u001b[0m retvals \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin_l_bfgs_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[1;32m    657\u001b[0m     xopt, fopt, d \u001b[38;5;241m=\u001b[39m retvals\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:197\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# build options\u001b[39;00m\n\u001b[1;32m    186\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m'\u001b[39m: iprint,\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxcor\u001b[39m\u001b[38;5;124m'\u001b[39m: m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: maxls}\n\u001b[0;32m--> 197\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    200\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    201\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuncalls\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    202\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    203\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarnflag\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    204\u001b[0m f \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:286\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    574\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[1;32m    575\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    578\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 456\u001b[0m     f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/statsmodels/base/model.py:531\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/statsmodels/tsa/statespace/mlemodel.py:939\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complex_step:\n\u001b[1;32m    937\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[0;32m--> 939\u001b[0m loglike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomplex_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;66;03m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/statsmodels/tsa/statespace/kalman_filter.py:983\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;124;03mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;124;03m    The joint loglikelihood.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    981\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    982\u001b[0m                   MEMORY_CONSERVE \u001b[38;5;241m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[0;32m--> 983\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m loglikelihood_burn \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloglikelihood_burn\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    985\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglikelihood_burn)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
      "File \u001b[0;32m~/.venvs/entsoe/lib/python3.10/site-packages/statsmodels/tsa/statespace/kalman_filter.py:906\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_state(prefix\u001b[38;5;241m=\u001b[39mprefix, complex_step\u001b[38;5;241m=\u001b[39mcomplex_step)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m \u001b[43mkfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kfilter\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Automatically discover optimal order for SARIMAX model with `auto_arima`...\")\n",
    "start_p = 1\n",
    "start_q = 1\n",
    "max_p = 3\n",
    "max_q = 3\n",
    "start_P = 1\n",
    "start_Q= 1\n",
    "max_P = 2\n",
    "max_Q = 2\n",
    "model = auto_arima(data, \n",
    "                   start_p=start_p, \n",
    "                   d=d, \n",
    "                   start_q=start_q,\n",
    "                   max_p=max_p,\n",
    "                   max_q=max_q,\n",
    "                   start_P=start_P,\n",
    "                   start_Q=start_Q,\n",
    "                   max_P=max_P,\n",
    "                   max_Q=max_Q,\n",
    "                   D=D, \n",
    "                   m=seasonal_cycle,\n",
    "                   trace=True\n",
    "                  )\n",
    "print(\"DONE.\")\n",
    "print(model)\n",
    "print(type(model))\n",
    "model.summary()\n",
    "\n",
    "with open('arima.pkl', 'wb') as pkl:\n",
    "    pickle.dump(model, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fcd0f9-8767-4e65-a214-12ac56795b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)\n",
    "model.summary()\n",
    "# Serialize model.\n",
    "with open('sarima.pkl', 'wb') as pkl:\n",
    "    pickle.dump(model, pkl)\n",
    "\n",
    "# You can still make predictions from the model at this point\n",
    "model.predict(n_periods=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d0773-5c9a-40de-bb56-f178d02da48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arima.pkl', 'rb') as pkl:\n",
    "    pickle_preds = pickle.load(pkl).predict(n_periods=5)\n",
    "print(pickle_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac3f43-0441-4ddb-9dba-12934cad4123",
   "metadata": {},
   "source": [
    "## Refreshing your SARIMAX models\n",
    "There are two ways to keep models up to date with `pmdarima`:\n",
    "1. Periodically, a model will need to be refreshed given new observations. One can either re-use `auto-arime`-estimated order terms or re-fitting altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for header in SarimaData.original_headers:\n",
    "    # Original data.\n",
    "    data = SarimaData.df[header]\n",
    "    dates = [pd.to_datetime(d).strftime('%Y-%m-%d') for d in data.index.to_series().dt.date.drop_duplicates().tolist()]\n",
    "    # Get train fraction from original data.\n",
    "    data_train = SarimaData.df[header].head(train_days * seasonal_cycle)\n",
    "    dates_train = [pd.to_datetime(d).strftime('%Y-%m-%d') for d in data_train.index.to_series().dt.date.drop_duplicates().tolist()]\n",
    "    # Get test fraction from original data.\n",
    "    data_test = SarimaData.df[header].tail(test_days * seasonal_cycle)\n",
    "    dates_test = [pd.to_datetime(d).strftime('%Y-%m-%d') for d in data_test.index.to_series().dt.date.drop_duplicates().tolist()]\n",
    "    \n",
    "    auto_arima(data.values, m=seasonal_cycle, seasonal=True, stationary=False, information_criterion='aic', test='kpss', seasonal_test='ocsb', trend=None, method='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150eaa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
